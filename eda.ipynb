{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MovieLens Preprocessing: Build cleaned_movies.csv\n\nThis notebook loads the MovieLens small dataset, cleans movie titles and genres, computes per-movie average ratings and normalized scores, joins TMDb IDs for posters, and saves a compact `cleaned_movies.csv` for the Streamlit hybrid recommender.\n\nDatasets used (from `ml-latest-small 2/`):\n- `movies.csv` (movieId, title, genres)\n- `ratings.csv` (userId, movieId, rating, timestamp)\n- `links.csv` (movieId, imdbId, tmdbId)\n\nOutput:\n- `/workspace/cleaned_movies.csv` with columns: `movieId`, `tmdbId`, `title` (lowercase), `genres_text`, `avg_rating`, `norm_rating`, `rating_count`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_DIR = Path('ml-latest-small 2')\n",
        "MOVIES_CSV = DATA_DIR / 'movies.csv'\n",
        "RATINGS_CSV = DATA_DIR / 'ratings.csv'\n",
        "LINKS_CSV = DATA_DIR / 'links.csv'\n",
        "OUTPUT_CSV = Path('cleaned_movies.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "movies = pd.read_csv(MOVIES_CSV)\n",
        "ratings = pd.read_csv(RATINGS_CSV)\n",
        "links = pd.read_csv(LINKS_CSV)\n",
        "movies.head(), ratings.head(), links.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Clean titles and genres\n",
        "movies['title'] = movies['title'].fillna('').str.strip().str.lower()\n",
        "movies['genres'] = movies['genres'].fillna('(no genres listed)')\n",
        "# Split and normalize genres\n",
        "movies['genres_list'] = movies['genres'].str.split('|')\n",
        "movies['genres_list'] = movies['genres_list'].apply(lambda lst: [g.strip().lower().replace('-', ' ') for g in lst] if isinstance(lst, list) else [])\n",
        "movies['genres_text'] = movies['genres_list'].apply(lambda lst: ' '.join(sorted(set(lst))))\n",
        "movies[['movieId','title','genres_text']].head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compute average rating and counts per movie\n",
        "ratings = ratings.dropna(subset=['movieId','rating'])\n",
        "agg = ratings.groupby('movieId').agg(avg_rating=('rating','mean'), rating_count=('rating','size')).reset_index()\n",
        "# Normalize avg_rating between 0 and 1\n",
        "if not agg.empty:\n",
        "    min_r, max_r = agg['avg_rating'].min(), agg['avg_rating'].max()\n",
        "    if max_r > min_r:\n",
        "        agg['norm_rating'] = (agg['avg_rating'] - min_r) / (max_r - min_r)\n",
        "    else:\n",
        "        agg['norm_rating'] = 0.5\n",
        "else:\n",
        "    agg['norm_rating'] = pd.Series(dtype=float)\n",
        "agg.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Merge datasets\n",
        "df = movies.merge(links[['movieId','tmdbId']], on='movieId', how='left')\n",
        "df = df.merge(agg, on='movieId', how='left')\n",
        "# Fill missing ratings\n",
        "df['avg_rating'] = df['avg_rating'].fillna(0.0)\n",
        "df['norm_rating'] = df['norm_rating'].fillna(0.0)\n",
        "df['rating_count'] = df['rating_count'].fillna(0).astype(int)\n",
        "# Clean tmdbId to int where possible\n",
        "def to_int_or_none(x):\n",
        "    try:\n",
        "        xi = int(x)\n",
        "        return xi if xi > 0 else np.nan\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "df['tmdbId'] = df['tmdbId'].apply(to_int_or_none)\n",
        "# Select columns and save\n",
        "out_cols = ['movieId','tmdbId','title','genres_text','avg_rating','norm_rating','rating_count']\n",
        "cleaned = df[out_cols].copy()\n",
        "cleaned.to_csv(OUTPUT_CSV, index=False)\n",
        "cleaned.head(10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now you can run the Streamlit app which loads `cleaned_movies.csv`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualization: Top Genres (bar) and Rating Distribution (hist)\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "# Ensure `cleaned` exists; if not, read from disk\n",
        "try:\n",
        "    cleaned\n",
        "except NameError:\n",
        "    cleaned = pd.read_csv('cleaned_movies.csv')\n",
        "\n",
        "# Top genres bar plot\n",
        "genres_flat = []\n",
        "for g in cleaned['genres_text'].fillna(''):\n",
        "    genres_flat += str(g).split()\n",
        "\n",
        "if genres_flat:\n",
        "    genre_counts = pd.Series(genres_flat).value_counts().head(10)\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "    sns.barplot(x=genre_counts.values, y=genre_counts.index, ax=ax, palette=\"Blues_r\")\n",
        "    ax.set_title('Top 10 Genres')\n",
        "    ax.set_xlabel('Count')\n",
        "    ax.set_ylabel('Genre')\n",
        "    plt.show()\n",
        "\n",
        "# Rating distribution histogram (average rating per movie)\n",
        "fig2, ax2 = plt.subplots(figsize=(7, 4))\n",
        "sns.histplot(cleaned['avg_rating'], bins=20, kde=False, ax=ax2, color=\"#4c72b0\")\n",
        "ax2.set_title('Average Rating Distribution (per Movie)')\n",
        "ax2.set_xlabel('Average Rating')\n",
        "ax2.set_ylabel('Number of Movies')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "3cdff4e4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Pairplot of rating metrics\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set_theme(style=\"ticks\")\n",
        "\n",
        "try:\n",
        "    cleaned\n",
        "except NameError:\n",
        "    cleaned = pd.read_csv('cleaned_movies.csv')\n",
        "\n",
        "pair_cols = ['avg_rating', 'norm_rating', 'rating_count']\n",
        "subset = cleaned[pair_cols].copy()\n",
        "# Avoid extremely skewed scales by clipping rating_count for nicer plots\n",
        "subset['rating_count_clipped'] = subset['rating_count'].clip(upper=subset['rating_count'].quantile(0.99))\n",
        "\n",
        "sns.pairplot(\n",
        "    subset.rename(columns={'rating_count_clipped': 'rating_count (clipped)'}),\n",
        "    vars=['avg_rating', 'norm_rating', 'rating_count (clipped)'],\n",
        "    diag_kind='hist',\n",
        "    corner=True\n",
        ")\n",
        "plt.suptitle('Pairplot: avg_rating, norm_rating, rating_count', y=1.02)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "a2b8680d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train/test split for ratings and save to disk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "\n",
        "# Use cleaned ratings (dropna already applied earlier)\n",
        "try:\n",
        "    ratings\n",
        "except NameError:\n",
        "    import pandas as pd\n",
        "    ratings = pd.read_csv('ml-latest-small 2/ratings.csv')\n",
        "    ratings = ratings.dropna(subset=['movieId','rating'])\n",
        "\n",
        "TRAIN_CSV = Path('ml-latest-small 2') / 'ratings_train.csv'\n",
        "TEST_CSV = Path('ml-latest-small 2') / 'ratings_test.csv'\n",
        "\n",
        "ratings_train, ratings_test = train_test_split(ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "ratings_train.to_csv(TRAIN_CSV, index=False)\n",
        "ratings_test.to_csv(TEST_CSV, index=False)\n",
        "\n",
        "len(ratings_train), len(ratings_test), TRAIN_CSV, TEST_CSV"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "075841a4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Recommender utilities for notebook use\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load cleaned data if not available\n",
        "try:\n",
        "    cleaned\n",
        "except NameError:\n",
        "    cleaned = pd.read_csv('cleaned_movies.csv')\n",
        "\n",
        "# Build TF-IDF on genres_text (content-based)\n",
        "_tf_vec = TfidfVectorizer(stop_words='english')\n",
        "_tfidf = _tf_vec.fit_transform(cleaned['genres_text'].fillna(''))\n",
        "\n",
        "# Build userâ€“item pivot from original ratings\n",
        "ratings_path = 'ml-latest-small 2/ratings.csv'\n",
        "ratings_nb = pd.read_csv(ratings_path, usecols=['userId','movieId','rating'])\n",
        "pivot_nb = ratings_nb.pivot_table(index='userId', columns='movieId', values='rating', aggfunc='mean').fillna(0.0)\n",
        "\n",
        "# Ensure pivot columns align to cleaned movieId order\n",
        "movie_ids = cleaned['movieId']\n",
        "missing_cols = [m for m in movie_ids if m not in pivot_nb.columns]\n",
        "for m in missing_cols:\n",
        "    pivot_nb[m] = 0.0\n",
        "pivot_nb = pivot_nb.loc[:, movie_ids]\n",
        "\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def recommend_content(title: str, k: int = 10) -> pd.DataFrame:\n",
        "    idx_list = cleaned.index[cleaned['title'] == title.lower()].tolist()\n",
        "    if not idx_list:\n",
        "        raise ValueError('Title not found')\n",
        "    idx = idx_list[0]\n",
        "    sims = cosine_similarity(_tfidf[idx], _tfidf).ravel()\n",
        "    df = cleaned.copy()\n",
        "    df['score'] = sims\n",
        "    df = df[df.index != idx]\n",
        "    return df.sort_values('score', ascending=False).head(k)[['title','genres_text','avg_rating','score']]\n",
        "\n",
        "\n",
        "def recommend_item_item(title: str, k: int = 10) -> pd.DataFrame:\n",
        "    idx_list = cleaned.index[cleaned['title'] == title.lower()].tolist()\n",
        "    if not idx_list:\n",
        "        raise ValueError('Title not found')\n",
        "    idx = idx_list[0]\n",
        "    target_vec = pivot_nb.iloc[:, idx].values.astype(float)\n",
        "    M = pivot_nb.values.astype(float)\n",
        "    num = M.T @ target_vec\n",
        "    den = (norm(M, axis=0) * norm(target_vec) + 1e-12)\n",
        "    sims = np.nan_to_num(num / den)\n",
        "    df = cleaned.copy()\n",
        "    df['score'] = sims\n",
        "    df = df[df.index != idx]\n",
        "    return df.sort_values('score', ascending=False).head(k)[['title','genres_text','avg_rating','score']]\n",
        "\n",
        "\n",
        "def recommend_hybrid(title: str, k: int = 10, w_content: float = 0.7, w_cf: float = 0.3) -> pd.DataFrame:\n",
        "    idx_list = cleaned.index[cleaned['title'] == title.lower()].tolist()\n",
        "    if not idx_list:\n",
        "        raise ValueError('Title not found')\n",
        "    idx = idx_list[0]\n",
        "    content = cosine_similarity(_tfidf[idx], _tfidf).ravel()\n",
        "    target_vec = pivot_nb.iloc[:, idx].values.astype(float)\n",
        "    M = pivot_nb.values.astype(float)\n",
        "    num = M.T @ target_vec\n",
        "    den = (norm(M, axis=0) * norm(target_vec) + 1e-12)\n",
        "    item = np.nan_to_num(num / den)\n",
        "    final = w_content * content + w_cf * item\n",
        "    df = cleaned.copy()\n",
        "    df['score'] = final\n",
        "    df = df[df.index != idx]\n",
        "    return df.sort_values('score', ascending=False).head(k)[['title','genres_text','avg_rating','score']]"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "5178ce30"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build itemâ€“item CF pivot on train split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "\n",
        "ratings_train = pd.read_csv('ml-latest-small 2/ratings_train.csv')\n",
        "\n",
        "# Align to cleaned movieIds\n",
        "pivot_train = ratings_train.pivot_table(index='userId', columns='movieId', values='rating', aggfunc='mean').fillna(0.0)\n",
        "movie_ids = cleaned['movieId']\n",
        "missing_cols = [m for m in movie_ids if m not in pivot_train.columns]\n",
        "for m in missing_cols:\n",
        "    pivot_train[m] = 0.0\n",
        "pivot_train = pivot_train.loc[:, movie_ids]\n",
        "\n",
        "# Helper for item similarity from train\n",
        "M_train = pivot_train.values.astype(float)\n",
        "\n",
        "def item_sim_vector_from_train(item_index: int) -> np.ndarray:\n",
        "    target_vec = M_train[:, item_index]\n",
        "    num = M_train.T @ target_vec\n",
        "    den = (norm(M_train, axis=0) * norm(target_vec) + 1e-12)\n",
        "    return np.nan_to_num(num / den)\n",
        "\n",
        "print('Train pivot shape (users x items):', pivot_train.shape)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "74cd663a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Demo: Try content-based, item-item CF, and hybrid\n",
        "# Choose a title (lowercase) that exists in cleaned['title']\n",
        "example_title = 'toy story (1995)'.lower()\n",
        "\n",
        "try:\n",
        "    print('Content-based:')\n",
        "    display(recommend_content(example_title, k=10))\n",
        "    print('\\nItem-item CF:')\n",
        "    display(recommend_item_item(example_title, k=10))\n",
        "    print('\\nHybrid (0.7 content, 0.3 CF):')\n",
        "    display(recommend_hybrid(example_title, k=10, w_content=0.7, w_cf=0.3))\n",
        "except ValueError as e:\n",
        "    print('Error:', e)\n",
        "    print('Available example titles:', cleaned['title'].head(10).tolist())"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "66bd5993"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}